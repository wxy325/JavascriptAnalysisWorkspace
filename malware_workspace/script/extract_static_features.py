from __future__ import division
import os
import re
import sys
sys.path.append('../pynarcissus')
from pynarcissus import jsparser
from bs4 import BeautifulSoup



# @param scripts Array[String] Array of contents of javascripts inside a single webpage
# @return Array[Number]  Array of feature values in a single webpage. The features value of more than one
#                          javascripts inside a single webpage should be merged together in to one array
#                          Please record the meaning of every features in https://docs.google.com/spreadsheets/d/1OQ3ae6dfGrREFBgLj0iQDvi_VuwRELjKBtx5G_qsNOs/edit?usp=sharing

a = [1,2,3]
b = ','.join(str(b) for b in a)
print(b)

def getAlphaPercentage(word):
    wordlength = len(word)
    alphacount = sum(c.isalpha() for c in word)
    return round((alphacount / wordlength)*100)
    

def getVoulPercentage(word):
    wordlength = len(word)
    voullength = word.count('a')
    voullength += word.count('e')
    voullength += word.count('i')
    voullength += word.count('o')
    voullength += word.count('u')

    return round((voullength / wordlength)*100)
    

def hasNoRep(word):
    pattern = re.compile(r'([a-zA-Z0-9])\1{2,}')
    if len(re.findall(pattern, word)) == 0:
        return True
    else:
        return False
    

def getReadablePercentage(stringArray):
    totalWordCount = len(stringArray)
    if totalWordCount == 0:
        return 0
    readbleWordCount = 0
    for word in stringArray:
        if len(word) == 0:
            pass
        alpha = getAlphaPercentage(word)
        voul = getVoulPercentage(word)
        if (alpha > 70 and voul > 20 and voul < 60 and len(word) < 15 and hasNoRep(word)):
            readbleWordCount += 1
    return round((readbleWordCount / totalWordCount)*100)
    

def getWhitespacePercentage(string):
    whitespaceRE = re.compile(r'\s')
    whitespace = len(re.findall(whitespaceRE, string))
    return round(whitespace / len(string)*100)
    

def getCPL(script):
    lengths = []
    scriptlines = script.splitlines()
    for line in scriptlines:
        lengths.append(len(line))
    return round(reduce(lambda x, y: x + y, lengths) / len(lengths))

def getStringLength(string):
    averageStringLength = 0
    values = []
    try:
        parsedScript = str(jsparser.parse(string))
        lines = parsedScript.splitlines()
        for index, line in enumerate(lines):
            if 'type: STRING' in line:
                nextline = index + 1
                while 'value:' not in lines[nextline]:
                    nextline += 1
                values.append(len(lines[nextline].split('value: ')[1]))

        if values:
            averageStringLength = round(reduce(lambda x, y: x + y, values) / len(values))
        else:
            averageStringLength = -1
    except:
        averageStringLength = -1

    return averageStringLength
    

def extract_features(scripts):
    evalInst = re.compile(r'eval')
    wordInst = re.compile(r'\b[a-zA-Z0-9]+\b')
    readableList = []
    whitespaceList = []
    cplList = []
    slList = []
    evalCount = 0

    for script in scripts:
        if len(script) == 0:
            continue
        evalCount = 0
        evalMatch = re.findall(evalInst, script)
        wordmatch = re.findall(wordInst, script)
        evalCount += len(evalMatch)
        cplList.append(getCPL(script))
        readableList.append(getReadablePercentage(wordmatch))
        whitespaceList.append(getWhitespacePercentage(script))
        slList.append(getStringLength(script))


    if readableList:
        averageReadable = int(round(reduce(lambda x, y: x + y, readableList) / len(readableList)))
    else:
        averageReadable = -1
    if whitespaceList:
        averageWhitespace = int(round(reduce(lambda x, y: x + y, whitespaceList) / len(whitespaceList)))
    else: 
        averageWhitespace = -1
    if cplList:
        averageCPL = int(round(reduce(lambda x,y: x + y, cplList) / len(cplList)))
    else:
        averageCPL = -1
    if slList:
        averageSL = int(round(reduce(lambda x,y: x + y, slList) / len(slList)))
    else:
        averageSL = -1
#  [average human readable code, number of eval() methods, average percentage of whitespace, average number of charachters per line, average length of strings]
    return [averageReadable, evalCount, averageWhitespace, averageCPL, averageSL]

def extract_malicious_feature():
    feature_rows = []

    # pattern = re.compile(r'<\s*script\s*[^>]*>([\s\S]*?)</script>', re.M | re.S | re.I)

    script_dir = os.path.dirname(os.path.realpath(__file__))
    renamed_malware_base = os.path.join(script_dir, '../data/obfuscated-malicious-output')
    output_feature_files = os.path.join(script_dir, '../out_feature/obfuscated_malicious_static_features.csv')

    dir_list = os.listdir(renamed_malware_base)
    for dir_base in dir_list:
        full_dir_base = os.path.join(renamed_malware_base, dir_base)

        for root, dirs, files in os.walk(full_dir_base):
            for f in files:
                file_full_path = os.path.join(root, f)
                with open(file_full_path) as input_file:
                    content = input_file.read()

                    soup = BeautifulSoup(content, 'html.parser')
                    scripts = soup.find_all('script')
                    match_results = []
                    for s in scripts:
                        match_results.append(s.get_text())

                    if len(match_results) == 0:
                        print('no scripts in file! ' + file_full_path)
                    else:
                        feature_row = extract_features(match_results)
                        feature_rows.append(feature_row)
                        print (feature_row)

    with open(output_feature_files, 'w') as f:
        for row in feature_rows:
            f.write(','.join(str(b) for b in row))
            f.write('\n')

def extract_benign_features():
    feature_rows = []

    # pattern = re.compile(r'<\s*script\s*[^>]*>([\s\S]*?)</script>', re.M | re.S | re.I)

    script_dir = os.path.dirname(os.path.realpath(__file__))
    # renamed_malware_base = os.path.join(script_dir, '../data/benign_dataset')
    # output_feature_files = os.path.join(script_dir, '../out_feature/benign_static_features.csv')
    renamed_malware_base = os.path.join(script_dir, '../data/obfuscated-benign-output')
    output_feature_files = os.path.join(script_dir, '../out_feature/obfuscated_benign_static_features.csv')

    file_without_scripts = []

    for root, dirs, files in os.walk(renamed_malware_base):
        for f in files:
            file_full_path = os.path.join(root, f)
            with open(file_full_path) as input_file:
                content = input_file.read()

                soup = BeautifulSoup(content, 'html.parser')
                scripts = soup.find_all('script')
                match_results = []
                for s in scripts:
                    match_results.append(s.get_text())

                if len(match_results) == 0:
                    print('no scripts in file! ' + file_full_path)
                    file_without_scripts.append(file_full_path)
                else:
                    # continue
                    feature_row = extract_features(match_results)
                    feature_rows.append(feature_row)
                    print (feature_row)
    # for f in file_without_scripts:
    #     os.remove(f)

    # '''
    with open(output_feature_files, 'w') as f:
        for row in feature_rows:
            f.write(','.join(str(b) for b in row))
            f.write('\n')
    # '''


if __name__ == '__main__':
    extract_benign_features()
    # extract_malicious_feature()



